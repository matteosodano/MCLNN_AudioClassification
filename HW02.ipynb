{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW02.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matteosodano/MCLNN_AudioClassification/blob/master/HW02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6LyGEfZlEGP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Import { vertical-output: true }\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "import keras\n",
        "from keras import applications, optimizers, regularizers\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.layers import Conv2D, AveragePooling2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Input, Model, Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import sklearn.metrics \n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlG0pZkC736v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Training and Test Set { vertical-output: true }\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "datadir = '/content/drive/My Drive/Homework2'\n",
        "trainingset = datadir+'/TrainingSet'\n",
        "testset = datadir + '/TrainingSet6'\n",
        "smarti_set = datadir + '/SMART-I'\n",
        "\n",
        "batch_size = 64\n",
        "input_shape = ()\n",
        "train_datagen = ImageDataGenerator(\n",
        "    # Generate batches of tensor image data with real-time data augmentation. \n",
        "    # The data will be looped over (in batches)\n",
        "    rescale = 1. / 255,\\\n",
        "    # rescaling factor. Defaults to None. If None or 0, no rescaling is applied, \n",
        "    # otherwise we multiply the data by the value provided\n",
        "    zoom_range=0.1,\\\n",
        "    # Float or [lower, upper]. Range for random zoom\n",
        "    rotation_range=10,\\\n",
        "    # Degree range for random rotations\n",
        "    width_shift_range=0.1,\\\n",
        "    # Fraction of total width\n",
        "    height_shift_range=0.1,\\\n",
        "    # Fraction of total height\n",
        "    horizontal_flip=False,\\\n",
        "    # Randomly flip inputs horizontally\n",
        "    vertical_flip=True\n",
        "    # Randomly flip inputs vertically\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    # Takes the path to a directory & generates batches of augmented data\n",
        "    directory=trainingset,\n",
        "    # String, path to the target directory. It should contain one subdirectory per class \n",
        "    target_size=(150, 240),\n",
        "    # Tuple of integers <height, width>\n",
        "    color_mode=\"rgb\",\n",
        "    # The images will be converted to have 3 channels\n",
        "    batch_size=batch_size,\n",
        "    # Size of the batches of data\n",
        "    class_mode=\"categorical\",\n",
        "    # \"categorical\" returns 2D array one-hot encoded labels\n",
        "    shuffle=True\n",
        "    # Shuffle the data\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rescale = 1. / 255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    directory=testset,\n",
        "    target_size=(150, 240),\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "smarti_datagen = ImageDataGenerator(\n",
        "    rescale = 1. / 255)\n",
        "\n",
        "smarti_generator = smarti_datagen.flow_from_directory(\n",
        "    directory=smarti_set,\n",
        "    target_size=(150, 240),\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "num_samples = train_generator.n\n",
        "num_classes = train_generator.num_classes\n",
        "input_shape = train_generator.image_shape\n",
        "\n",
        "classnames = [k for k,v in train_generator.class_indices.items()]\n",
        "\n",
        "print(\"Image input %s\" %str(input_shape))\n",
        "print(\"Classes: %r\" %classnames)\n",
        "\n",
        "print('Loaded %d training samples from %d classes.' %(num_samples,num_classes))\n",
        "print('Loaded %d test samples from %d classes.' %(test_generator.n,test_generator.num_classes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cF-oN_LKsfH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Random Images { vertical-output: true }\n",
        "n = len(classnames)\n",
        "x,y = train_generator.next()\n",
        "# x,y size is train_generator.batch_size\n",
        "\n",
        "for i in range(0,n):\n",
        "    image = x[i]\n",
        "    label = y[i].argmax() \n",
        "    print(classnames[label])\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0e3K1WZLGff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Neural Network { vertical-output: true }\n",
        "def MatNet(input_shape, num_classes):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    # C1 Convolutional Layer --- 2D convolution layer for spatial convolution over images\n",
        "    # 1. Dimensionality of the output space\n",
        "    # 2. When using this layer as the first layer in a model, provide the keyword argument input_shape\n",
        "    # 3. Size of the convolution kernel\n",
        "    # 4. An integer or tuple/list of 2 integers, specifying the strides of the \n",
        "    #    convolution along the height and width. Stride = how much do I slide\n",
        "    # 5. Padding = keep the same size by adding zeros\n",
        "    # 6. Activation function\n",
        "    model.add(Conv2D(32, input_shape=input_shape, kernel_size=(7,7), strides=(3,3), \n",
        "                     padding='same', activation='tanh'))\n",
        "    \n",
        "    # Invariance to local translations. Reduce the importance of detecting an information\n",
        "    # in a precise pixel \n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "    # Normalize the activations of the previous layer at each batch, i.e. applies a transformation \n",
        "    # that maintains the mean activation close to 0 and the activation standard deviation close to 1.\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "    # C2 Convolutional Layer \n",
        "    model.add(Conv2D(64, kernel_size=(6,6), strides=(2,2), padding='same', \n",
        "                     activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "    # C3 Convolutional Layer\n",
        "    model.add(Conv2D(96, kernel_size=(2,2), strides=(1,1), padding='valid', \n",
        "                     activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(1,1), padding='valid'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "    # Flatten: transforms the data representation from a 3D space to a 1D vector\n",
        "    model.add(Flatten())\n",
        "    \n",
        "    # D1 Dense Layer: regular densely-connected NN layer\n",
        "    # 1. Number of units\n",
        "    # 2. Activation function\n",
        "    model.add(Dense(300, activation='relu'))\n",
        "\n",
        "    # Dropout consists in randomly setting a fraction of input units to 0 \n",
        "    # at each update during training time, which helps prevent overfitting.\n",
        "    model.add(Dropout(0.33))\n",
        "\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "    # D2 Dense Layer\n",
        "    model.add(Dense(200, activation='relu'))\n",
        "    model.add(Dropout(0.33))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "    # D3 Dense Layer\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "    # D4 Dense Layer\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "    # Compile\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(), \n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        " \n",
        "# create the model\n",
        "model = MatNet(input_shape,num_classes)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMrecdbySRI0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Network Model { vertical-output: true }\n",
        "tf.keras.utils.plot_model(model)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KamfwuqSi1B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Training { vertical-output: true }\n",
        "\n",
        "stopping = EarlyStopping(monitor='val_acc', patience=3)\n",
        "\n",
        "steps_per_epoch=train_generator.n//train_generator.batch_size\n",
        "val_steps=test_generator.n//test_generator.batch_size+1\n",
        "\n",
        "try:\n",
        "    # Trains the model on data generated batch-by-batch by a Python generator\n",
        "    # 1. Generator that gives tuples, that form batches\n",
        "    # 2. Integer number of epochs to train the model. An epoch is an iteration over the entire data provided\n",
        "    # 3. number of steps (batches of samples) to yield from generator before declaring one epoch \n",
        "    #    finished and starting the next epoch\n",
        "    # 4. Generator for the test set\n",
        "    # 5. Total number of steps (batches of samples) to yield from test generator \n",
        "    #    before stopping at the end of every epoch\n",
        "    history = model.fit_generator(train_generator, epochs=30, verbose=1, \\\n",
        "                    steps_per_epoch=steps_per_epoch,\\\n",
        "                    validation_data=smarti_generator,\\\n",
        "                    validation_steps=val_steps)\n",
        "except KeyboardInterrupt:\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rzq7OC7nzICH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Save Model { vertical-output: true }\n",
        "models_dir = '/content/drive/My Drive/Homework2'\n",
        "\n",
        "def savemodel(model,problem):\n",
        "    filename = os.path.join(models_dir, '%s.h5' %problem)\n",
        "    model.save(filename)\n",
        "    print(\"\\nModel saved successfully on file %s\\n\" %filename)\n",
        "\n",
        "# Save the model\n",
        "savemodel(model,'HW02_MatNet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1PvySfyzViq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Performance { vertical-output: true }\n",
        "preds = model.predict_generator(test_generator,verbose=1,steps=val_steps)\n",
        "\n",
        "Ypred = np.argmax(preds, axis=1)\n",
        "Ytest = test_generator.classes \n",
        "\n",
        "print(classification_report(Ytest, Ypred, labels=None, target_names=classnames, digits=3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kmYDzCazhpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Confusion Matrix { vertical-output: true }\n",
        "def plot_confusion_matrix(cm, classes):\n",
        "    cm = pd.DataFrame(cm, index=classes, columns=classes)\n",
        "\n",
        "    heatmap = sns.heatmap(cm, annot=True, fmt=\"d\")\n",
        "    bottom, top = heatmap.get_ylim()\n",
        "    heatmap.set_ylim(bottom + 0.5, top - 0.5)\n",
        "  \n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "\n",
        "cnf_matrix = confusion_matrix(Ytest, Ypred)\n",
        "classes = ['Haze', 'Rainy', 'Snowy', 'Sunny']\n",
        "\n",
        "plot_confusion_matrix(cnf_matrix, classes)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe1SH4yvzwe-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Accuracy and Loss plots { vertical-output: true }\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uF_EeA3C71dK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Transfer Network { vertical-output: true }\n",
        "\n",
        "# Inception Net\n",
        "transfer_model = tf.keras.applications.InceptionResNetV2(\\\n",
        "    input_shape=input_shape,include_top=False, weights='imagenet', pooling='avg')\n",
        "model = tf.keras.Sequential([transfer_model, tf.keras.layers.Flatten(), \n",
        "                             tf.keras.layers.Dense(num_classes, activation='softmax')])\n",
        "\n",
        "# VGG16 Net\n",
        "#transfer_model = tf.keras.applications.vgg16.VGG16(include_top=False, weights='imagenet',\n",
        "#                                                   input_shape=input_shape,pooling='max')\n",
        "#model = tf.keras.Sequential([transfer_model,tf.keras.layers.Flatten(),\n",
        "#                             tf.keras.layers.Dense(num_classes, activation='softmax')])\n",
        "\n",
        "optimizer = 'adam'\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIWzgs7F71wM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Train Transfer Net { vertical-output: true }\n",
        "# fit the transferNet on the training data\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "#stopping = EarlyStopping(monitor='val_acc', patience=3)\n",
        "\n",
        "steps_per_epoch = train_generator.n//train_generator.batch_size\n",
        "val_steps = test_generator.n//test_generator.batch_size+1\n",
        "\n",
        "try:\n",
        "    history_transfer = model.fit_generator(train_generator, epochs=10, verbose=1,\n",
        "                    steps_per_epoch=steps_per_epoch,\\\n",
        "                    validation_data=test_generator,\\\n",
        "                    validation_steps=val_steps)\n",
        "except KeyboardInterrupt:\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpUQ9Lps715i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Performance { vertical-output: true }\n",
        "preds_t = model.predict_generator(test_generator,verbose=1,steps=val_steps)\n",
        "\n",
        "Ypred = np.argmax(preds_t, axis=1)\n",
        "Ytest = test_generator.classes \n",
        "\n",
        "print(classification_report(Ytest, Ypred, labels=None, target_names=classnames, digits=3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNimX7As8bmT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Confusion Matrix { vertical-output: true }\n",
        "def plot_confusion_matrix(cm, classes):\n",
        "    cm = pd.DataFrame(cm, index=classes, columns=classes)\n",
        "\n",
        "    heatmap = sns.heatmap(cm, annot=True, fmt=\"d\")\n",
        "    bottom, top = heatmap.get_ylim()\n",
        "    heatmap.set_ylim(bottom + 0.5, top - 0.5)\n",
        "  \n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "\n",
        "cnf_matrix = confusion_matrix(Ytest, Ypred)\n",
        "classes = ['Haze', 'Rainy', 'Snowy', 'Sunny']\n",
        "\n",
        "plot_confusion_matrix(cnf_matrix, classes)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74IaFiiJ8f6M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Accuracy and Loss plots { vertical-output: true }\n",
        "\n",
        "plt.plot(history_transfer.history['acc'])\n",
        "plt.plot(history_transfer.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history_transfer.history['loss'])\n",
        "plt.plot(history_transfer.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyygNmoBpnTw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Save Model { vertical-output: true }\n",
        "models_dir = '/content/drive/My Drive/Homework2'\n",
        "\n",
        "def savemodel(model,problem):\n",
        "    filename = os.path.join(models_dir, '%s.h5' %problem)\n",
        "    model.save(filename)\n",
        "    print(\"\\nModel saved successfully on file %s\\n\" %filename)\n",
        "\n",
        "# Save the model\n",
        "savemodel(model,'InceptionNet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZrXPJchp-8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Performances { vertical-output: true }\n",
        "#model.predict(smarti_generator)\n",
        "\n",
        "preds_t = model.predict_generator(smarti_generator)\n",
        "\n",
        "Ypred = np.argmax(preds_t, axis=1)\n",
        "Ytest = smarti_generator.classes \n",
        "#print(preds_t.shape, Ypred.shape, Ytest.shape)\n",
        "print(classification_report(Ytest, Ypred, labels=None, target_names=classnames, digits=3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FWicZXPwr6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Confusion Matrix { vertical-output: true }\n",
        "cnf_matrix = confusion_matrix(Ytest, Ypred)\n",
        "classes = ['Haze', 'Rainy', 'Snowy', 'Sunny']\n",
        "\n",
        "plot_confusion_matrix(cnf_matrix, classes)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5FhgyRBPYvC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Blind Test Set { vertical-output: true }\n",
        "blind_set = datadir + '/WeatherBlindTestSet'\n",
        "\n",
        "blind_datagen = ImageDataGenerator(\n",
        "    rescale = 1. / 255)\n",
        "\n",
        "blind_generator = blind_datagen.flow_from_directory(\n",
        "    directory=blind_set,\n",
        "    target_size=(150, 240),\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# load the best model\n",
        "model = load_model(datadir+'/InceptionNet.h5')\n",
        "\n",
        "blind_pred = model.predict(blind_generator)\n",
        "predictions = np.argmax(blind_pred, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO98RhpQWmWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Write CSV { vertical-output: true }\n",
        "def write_csv(pred):\n",
        "  drive.mount('/content/drive')\n",
        "  with open('/content/drive/My Drive/Homework2/1695082.csv', 'w') as csv:\n",
        "    len_p = len(predictions)\n",
        "    for i in range(0,len_p):\n",
        "      data = predictions[i]\n",
        "      if data == 0:\n",
        "        csv.write('HAZE\\n')\n",
        "      elif data == 1:\n",
        "        csv.write('RAINY\\n')\n",
        "      elif data == 2:\n",
        "        csv.write('SNOWY\\n')\n",
        "      elif data == 3:\n",
        "        csv.write('SUNNY\\n')\n",
        "  drive.flush_and_unmount()\n",
        "  return 0\n",
        "\n",
        "write_csv(predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}